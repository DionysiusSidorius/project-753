{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaADw6GgdL0sD8qdRHKT/+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Getting started"
      ],
      "metadata": {
        "id": "TGONOV9moRih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DionysiusSidorius/project-753.git"
      ],
      "metadata": {
        "id": "tehQU_gtHerE",
        "outputId": "f216e5fd-2215-4270-e6c6-0bd39c77f97a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'project-753'...\n",
            "remote: Enumerating objects: 601, done.\u001b[K\n",
            "remote: Counting objects: 100% (124/124), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 601 (delta 75), reused 4 (delta 4), pack-reused 477 (from 1)\u001b[K\n",
            "Receiving objects: 100% (601/601), 8.20 MiB | 6.22 MiB/s, done.\n",
            "Resolving deltas: 100% (361/361), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/project-753/spanish.csv', sep=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee2Bk_m6-Lg1",
        "outputId": "38582d52-5dbf-4d51-ced5-ae5ee4917f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-d79e48a46742>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
            "  df = pd.read_csv('/content/project-753/spanish.csv', sep=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Deleter"
      ],
      "metadata": {
        "id": "dIhw8F-KwKwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('lexemes.txt', 'w') as lex:\n",
        "  pass"
      ],
      "metadata": {
        "id": "Vt0v7FUvVi6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lexemes"
      ],
      "metadata": {
        "id": "3t8qXch3wCCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###nomina"
      ],
      "metadata": {
        "id": "RkyXRxp7FNZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NOUN(_V)\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+[aoeiuáóéíú]\\b\")) & ((df['POS'].str.strip() == 'extranj.')|(df['POS'].str.strip() == 'sust.'))\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    if not isinstance(other, str):\n",
        "          forms = set()\n",
        "    else:\n",
        "          forms = set([re.sub(r'(.+)s', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form.strip()+\".\" for form in forms if form.strip().count(' ') == 0]) if forms and list(forms)[0] else ''}\n",
        " gramm: noun\n",
        " paradigm: NOM\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "sJ-Y8kCtLhuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NOUN(_C)\n",
        "import re\n",
        "dict_noun_C = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r'.*(?!.[aoeiuáóéíú]|os).{2}')) & ((df['POS'].str.strip() == 'extranj.')|(df['POS'].str.strip() == 'sust.'))\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_C['WORD'], dict_noun_C['ADDITIONAL_INFO']):\n",
        "    forms = set([re.sub(r'(.+)es', r'\\1', form) if word[-2:]!='es' else re.sub(r'(.+ess?)es', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form.strip()+\".\" for form in forms if form.strip().count(' ') == 0]) if forms else ''}\n",
        " gramm: noun\n",
        " paradigm: NOM_C\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "0cP5x8QxWDMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NOUN(_os)\n",
        "import re\n",
        "dict_noun_os = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r'.+os\\b')) & (df['POS'].str.strip() == 'sust.')\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_os['WORD'], dict_noun_os['ADDITIONAL_INFO']):\n",
        "    forms = set(eval(other)['Formas atestiguadas:\\xa0'])\n",
        "    forms.discard(word)\n",
        "    if any([form[-2:]=='es' for form in forms]):\n",
        "      forms = [re.sub(r'(.+)es', r'\\1', form) for form in forms]\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form.strip()+\".\" for form in forms if form.strip().count(' ') == 0]) if forms else ''}\n",
        " gramm: noun\n",
        " paradigm: NOM_C\n",
        "\"\"\")\n",
        "    else:\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form.strip()+\".\" for form in forms if form.strip().count(' ') == 0]) if forms else ''}\n",
        " gramm: noun\n",
        " paradigm: NOM_os\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "JXFOSslhcQds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ADJ(_V)\n",
        "import re\n",
        "dict_adj_V = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+o\\b\")) & (df['POS'].str.strip() == 'adj.')\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_adj_V['WORD'], dict_adj_V['ADDITIONAL_INFO']):\n",
        "    word = re.sub(r'(.+)(o)', r'\\1', word)\n",
        "    if not isinstance(other, str):\n",
        "      forms = set()\n",
        "    else:\n",
        "      forms = set([re.sub(r'(.+)([oa]s?)', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word+'o'}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: adj\n",
        " paradigm: ADJ\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "OLZcBizz5csL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ADJ(_e)\n",
        "import re\n",
        "dict_adj_e = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+e\\b\")) & (df['POS'].str.strip() == 'adj.')\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_adj_e['WORD'], dict_adj_e['ADDITIONAL_INFO']):\n",
        "    word = re.sub(r'(.+)(e)', r'\\1', word)\n",
        "    if not isinstance(other, str):\n",
        "      forms = set()\n",
        "    else:\n",
        "      forms = set([re.sub(r'(.+)(es?)', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word+'e'}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: adj\n",
        " paradigm: ADJ_e\n",
        "\"\"\"\n",
        "  )"
      ],
      "metadata": {
        "id": "GFta1j929bCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ADJ(_C/_Ca)\n",
        "import re\n",
        "dict_adj_C = df[\n",
        "    (~df['WORD'].str.strip().str.contains(r'([aoeiuáóéíú]|os)$', regex=True, na=False)) & (df['POS'].str.strip() == 'adj.')\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_adj_C['WORD'], dict_adj_C['ADDITIONAL_INFO']):\n",
        "    if not isinstance(other, str):\n",
        "      forms = set()\n",
        "    else:\n",
        "      forms = set([re.sub(r'(.+)(es|(?<=a)s)\\b', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    if any([form[-1]=='a' for form in forms]):\n",
        "      forms = set([re.sub(r'(.+)(a)\\b', r'\\1', form) for form in forms])\n",
        "      forms.discard(word)\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: adj\n",
        " paradigm: ADJ_Ca\n",
        "\"\"\"\n",
        "    )\n",
        "    else:\n",
        "      forms.discard(word)\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: adj\n",
        " paradigm: ADJ_C\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "7baNiPlDAiP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ADJ(_os) - son numerales (ADJ_V) o simplemente adjetivos (ADJ_C(a))\n",
        "import re\n",
        "dict_noun_os = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r'.+os\\b')) & (df['POS'].str.strip() == 'adj.')\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_os['WORD'], dict_noun_os['ADDITIONAL_INFO']):\n",
        "    if re.fullmatch(r'.+ientos', word):\n",
        "      word = re.sub(r'(.+)os\\b', r'\\1', word)\n",
        "      forms = set([re.sub(r'(.+)[ao]s', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "      forms.discard(word)\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word+'os'}\n",
        " stem: {word}.{'|'+'|'.join([form.strip()+\".\" for form in forms if form.strip().count(' ') == 0]) if forms else ''}\n",
        " gramm: num\n",
        " paradigm: ADJ\n",
        "\"\"\")\n",
        "    elif word=='dos':\n",
        "      forms = set(eval(other)['Formas atestiguadas:\\xa0'])\n",
        "      forms.discard(word)\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form.strip()+\".\" for form in forms if form.strip().count(' ') == 0]) if forms else ''}\n",
        " gramm: num\n",
        " paradigm: ZERO\n",
        "\"\"\")\n",
        "    else:\n",
        "      forms = set(eval(other)['Formas atestiguadas:\\xa0'])\n",
        "      if any([re.fullmatch(r'.+as', form) for form in forms]):\n",
        "        forms = set([re.sub(r'(.+)([oa]s)', r'\\1', form) for form in forms])\n",
        "        word = re.sub(r'(.+)os', r'\\1', word)\n",
        "        forms.discard(word)\n",
        "        lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word+'os'}\n",
        " stem: {word}.{'|'+'|'.join([form.strip()+\".\" for form in forms if form.strip().count(' ') == 0]) if forms else ''}\n",
        " gramm: adj\n",
        " paradigm: ADJ\n",
        "\"\"\"\n",
        "    )\n",
        "      else:\n",
        "        forms = set([re.sub(r'(.+)(es|(?<=a)s)\\b', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "        forms.discard(word)\n",
        "        lex.write(\n",
        "f\"\"\"-lexeme\n",
        "  lex: {word}\n",
        "  stem: {word}.{'|'+'|'.join([form.strip()+\".\" for form in forms if form.strip().count(' ') == 0]) if forms else ''}\n",
        "  gramm: adj\n",
        "  paradigm: ADJ_C\n",
        "\"\"\"\n",
        "      )"
      ],
      "metadata": {
        "id": "m5PZTXhPNHW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Verba"
      ],
      "metadata": {
        "id": "ct9pxhDxZ8Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VERB(_ar)\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+ar\\b\")) &\n",
        "     ((df['POS'].str.strip() == 'vrb.')|(df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "    (\n",
        "        (~df['WORD'].isin({'adar', 'atacir', 'azar', 'azingar', 'bezoar', 'cantar', 'cuer', 'haber', 'juglar', 'lugar', 'mar', 'menester', 'mujer', 'par', 'pesar', 'poder', 'saber', 'ser'}))\n",
        "        | df.index.isin({5363, 7671, 7804, 8682})\n",
        "    ))\n",
        "]\n",
        "tags = {'fut. indic. 2 pl.', 'fut. subj. 1 sing.', 'plusc. simp. 2 sing.', 'pot. simp. 1 sing.', 'imper. 2 pl.', 'fut. subj. 3 pl.', 'fut. subj. 2 pl.', 'pot. simp. 3 pl.', 'pret. 2 sing.', 'pres. indic. 1pl.', 'imperf. indic. 3 pl.', 'fut. perf. indic. 1 pl.', 'infinit. comp.', 'pret. anter. 3pl.', 'fut. subj. 3pl.', 'fut. perf. subj. 3 pl.', 'fut. subj. 3 sing.', 'p. p.', 'pret. perf. indic. 1 pl.', 'pres. subj. 3pl.', 'pret. perf. subj. 2 sing.', 'imperf. subj. 3 sing.', 'pret. plusc. indic. 3 pl.', 'fut. perf. subj. 2 pl.', 'fut. perf. subj. 1 pl.', 'pot. simp. 2 pl.', 'pret. perf. indic. 2 sing.', 'pret. plusc. subj. 3 sing.', 'imperf. indic. 1 sing.', 'ger. comp.', 'pres. subj. 1 pl.', 'pot. simp. 1pl.', 'plusc. si mp. 3 sing.', 'imperf. indic. 3pl.', 'fut. indic. 1pl.', 'pret. plusc. subj. 2 sing.', 'imperf. indic. 3 sing.', 'plusc. simp. 1 pl.', 'pres. indic. 3 sing.', 'pret. plusc. subj. 2 pl.', 'pres. subj. 1 sing.', 'pot. simp. 3 sing.', 'pret. perf. indic. 2 pl.', 'pres. indic. 1 pl.', 'pot. simp. 2 sing.', 'pret. 2 pl.', 'pret. perf. indic. 3 sing.', 'pret. perf. subj. 3 sing.', 'pot. simp. 3pl.', 'fut. perf. indic. 3 pl.', 'pret. anter. 3 pl.', 'plusc. simp. comp. 3 sing.', 'fut. perf. indic. 2 sing.', 'pres. subj. 2sing.', 'pret. plusc. indic. 3 sing.', 'plusc. simp. 2 pl.', 'pret. plusc. indic. 1 pl.', 'pres. subj. 1pl.', 'imperf. indic. 1 pl.', 'plusc. simp. comp. 3 pl.', 'pres. subj. 2 pl.', 'imper. 2pl.', 'fut. indic. 2pl.', 'pret. plusc. subj. 3pl.', 'pret. anter. 2 pl.', 'pot. simp. 1 pl.', 'fut. indic. 3pl.', 'pret. 2pl.', 'pres. subj. 3 sing.', 'pret. 1 sing.', 'fut. perf. subj. 3 sing.', 'pret. perf. indic. 3 pl.', 'plusc. simp. 1 sing.', 'pres. subj. 2pl.', 'infinit.', 'fut. indic. 3 pl.', 'imperf. indic. 2 sing.', 'pret. plusc. subj. 1 pl.', 'pret. anter. 3 sing.', 'pret. anter. 1 pl.', 'pres. indic. 3pl.', 'pret. perf. indic. 3pl.', 'imperf. subj. 1 sing.', 'plusc. simp. comp. 1 pl.', 'fut. indic. 3 sing.', 'pres. subj. 2 sing.', 'pres. subj. 3 pl.', 'fut. perf. subj. 2 sing.', 'ger.', 'imperf. subj. 3 pl.', 'fut. subj. 1 pl.', 'pres. indic. 1 sing.', 'plusc. simp. 3 sing.', 'pret. perf. indic. 1 sing.', 'pret. plusc. indic. 2 sing.', 'pret. perf. subj. 2 pl.', 'fut. indic. 2 sing.', 'fut. subj. 2 sing.', 'pret. 1pl.', 'pret. plusc. subj. 3 pl.', 'imperf. indic. 2pl.', 'imperf. subj. 2 sing.', 'pres. indic. 2pl.', 'pret. 3 pl.', 'imperf. subj. 2 pl.', 'imperf. indic. 2 pl.', 'pret. plusc. indic. 2 pl.', 'p. a.', 'plusc. simp. 3 pl.', 'fut. indic. 1 sing.', 'pot. comp. 3 pl.', 'pret. anter. 2 sing.', 'imper. 2 sing.', 'pret. perf. subj. 1 pl.', 'imperf. subj. 1pl.', 'pret. plusc. indic. 1 sing.', 'pret. perf. subj. 3 pl.', 'pres. indic. 2 pl.', 'plusc. simp. 3pl.', 'pres. indic. 2 sing.', 'pret. plusc. subj. 1 sing.', 'imperf. indic.', 'imperf. subj. 1 pl.', 'fut. indic. 1 pl.', 'pret. 3 sing.', 'pres. indic. 3 pl.', 'pret. perf. indic. 1pl.', 'pret. anter. 1 sing.', 'imperf. indic. 1pl.', 'pret. perf. indic. 2pl.', 'pret. 3pl.', 'pret. plusc. indic. 3pl.', 'pret. 1 pl.', 'imperf. subj. 3pl.'}\n",
        "tatags = '|'.join(tags).replace('.', '\\.')\n",
        "# clas = set()\n",
        "pattern = r'(o|((a|e)((r(\\(?[smtnl]?(e|a|o)?s?\\)s?)?i?(a|e)|(b|u)a|ss?e)?(s(t(es?)?)?|mos|des|(ro)?n)?|l\\(?l(e|a|o)?s?\\)s?|r(\\(?[smtn]?(e|a|o)?s?\\)s?)?|t|ndo|(d([ao]s?)?)?)))$'\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    if not isinstance(other, str):\n",
        "      forms = set()\n",
        "    else:\n",
        "      forms = set(eval(other)['Formas atestiguadas:\\xa0'] if other!= '{}' else [])\n",
        "      wirds = set()\n",
        "      for form in forms:\n",
        "        for subs in form.split(';'):\n",
        "          two = subs.split('–')\n",
        "          if len(two)==2:\n",
        "            # clas.add(two[0].strip())\n",
        "            wirds.add(re.sub(tatags, '', two[1]).strip())\n",
        "          else: wirds.add(re.sub(tatags, '', two[0]).strip())\n",
        "      #forms = set([re.sub(r'(.+)([oa]s?)', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    wirds = set(re.sub(pattern, '', p) for p in wirds if p.count(' ')==0 and p.count('(')==0 and p.count(')')==0)\n",
        "    wirds.discard(word[:-2])\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word[:-2]}.{'|'+'|'.join([form+\".\" for form in wirds]) if wirds and list(wirds)[0] else ''}\n",
        " gramm: verb\n",
        " paradigm: V_{word[-2]}\n",
        "\"\"\"\n",
        "    )\n",
        "    # lex.write(f\"{word}, ':', {wirds}\\n\")"
      ],
      "metadata": {
        "id": "6Z52ZokHZ-Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'(o|((a|e)((r(\\(?[smtnl]?(e|a|o)?s?\\)s?)?i?(a|e)|(b|u)a|ss?e)?(s(t(es?)?)?|mos|des|(ro)?n)?|l\\(?l(e|a|o)?s?\\)s?|r(\\(?[smtn]?(e|a|o)?s?\\)s?)?|t|ndo|(d([ao]s?)?)?)))$'\n",
        "a = {'peno', 'peneste', 'penando', 'penaua', 'penan', 'penes', 'penassen', 'penades', 'penauan', 'penado', 'penados', 'penasse', 'penar', 'penarie', 'penare', 'penaron', 'penamos', 'penara', 'penadas', 'penaredes', 'penad'}\n",
        "a = {'amostro', 'muestra', 'mostrasse', 'amostrar(l)an', 'mostrastes', 'mostreste', 'mostrad', 'mostrara', 'muestran', 'muestren', 'amostrasse', 'mostrassen', 'mostrat', 'mostrar(s)a', 'mostradas', 'mostrarie', 'muestras', 'muestre', 'mostresse', 'amostrare', 'mostre', 'mostremos', 'mostrest', 'mostraria', 'amostrarien', 'mostrare', 'mostrados', 'mostro', 'mostraremos', 'mostral(le)', 'amuestren', 'mostrauan', 'mostra', 'mostramos', 'muestres', 'amostren', 'mostraua', 'amostrad', 'mostrando', 'amuestra', 'amostre', 'amostramos', 'mostredes', 'mostrado', 'mostraran', 'mostraredes', 'mostar', 'amuestras', 'mostraren', 'amuestran', 'mostraron', 'amostrado', 'mostrarien', 'mostrada', 'amostradas', 'amostra', 'mostrar', 'mostrades', 'amostrar', 'amostrados', 'amostrada', 'mostraras', 'mostrares'}\n",
        "a = {'enuiaron', 'ouo enuiado', 'embiarie', 'enuiaran', 'en uiasse', 'enbiado', 'enuia', 'enbie', 'enuiados', 'enuiase', 'enuiades', 'enuiauan', 'enbiassen', 'embiado', 'embio', 'enuian', 'enuiasses', 'enuiest', 'enujaua', 'enuiassemos', 'enuies', 'enuiar (las) as', 'enbiasse', 'enbiastes', 'auia enbiada', 'enbiaria', 'enuio', 'enbiare', 'enuiara', 'enbiarie', 'enbjasse', 'enuiat', 'enuiar', 'enuiast', 'auie enbiados', 'enbiara', 'enuiando', 'enuiaramos', 'enuiassen', 'ouo enbiada', 'enuiamos', 'enuiedes', 'enuiemos', 'enbiemos', 'enbiaron', 'enuiaries', 'enbies', 'enbiad', 'ouieren enuiado', 'embiaron', 'enuiaras', 'enuiadas', 'enujauan', 'enbieste', 'enujo', 'enuie', 'enuiaredes', 'embiar', 'enuiar (me l)edes', 'enbiades', 'enuiar (la) a', 'enbiase', 'en uiado', 'enuiaua', 'auia enbiado', 'enbiados', 'enuiare', 'enviado', 'en uiaron', 'enuiarie', 'enbiaran', 'enbiada', 'enuiarien', 'enuiaremos', 'enuiada', 'enuiaste', 'ouieron enuiadas', 'enuiastes', 'enbiauan', 'embie', 'ouiesse enuiada', 'enuiasse', 'enuiado as', 'enuien', 'enbiaua', 'embia', 'enujados', 'auien enuiado', 'enuias', 'embiastes', 'enuiares', 'enuiaren', 'emuio', 'enuiado', 'enbiar', 'enbiedes', 'emuiar', 'embian', 'embiaua', 'enbiarien', 'enbio', 'enuiad', 'auie enuiado', 'enuieste', 'enbia'}\n",
        "a = {'escandalizan', 'escandalizemos', 'escandalizando', 'escandalizarien', 'escandalizar', 'escandalizados', 'escandalizasse', 'escandalizassen', 'escandalizado', 'escandalizen'}\n",
        "\n",
        "# a = {'amal(le)'}\n",
        "a = set(re.sub(pattern, '', p) for p in a if p.count(' ')==0)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "a06D_yis9-s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VERB(_er/ir)\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+[ei]r\\b\")) &\n",
        "          ((df['POS'].str.strip() == 'vrb.')|(df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "    (\n",
        "        (~df['WORD'].isin({'adar', 'atacir', 'azar', 'azingar', 'bezoar', 'cantar', 'cuer', 'haber', 'juglar', 'lugar', 'mar', 'menester', 'mujer', 'par', 'pesar', 'poder', 'saber', 'ser'}))\n",
        "        | (df.index.isin({5363, 7671, 7804, 7682, 8346}))\n",
        "    ))\n",
        "]\n",
        "tags = {'fut. indic. 2 pl.', 'fut. subj. 1 sing.', 'plusc. simp. 2 sing.', 'pot. simp. 1 sing.', 'imper. 2 pl.', 'fut. subj. 3 pl.', 'fut. subj. 2 pl.', 'pot. simp. 3 pl.', 'pret. 2 sing.', 'pres. indic. 1pl.', 'imperf. indic. 3 pl.', 'fut. perf. indic. 1 pl.', 'infinit. comp.', 'pret. anter. 3pl.', 'fut. subj. 3pl.', 'fut. perf. subj. 3 pl.', 'fut. subj. 3 sing.', 'p. p.', 'pret. perf. indic. 1 pl.', 'pres. subj. 3pl.', 'pret. perf. subj. 2 sing.', 'imperf. subj. 3 sing.', 'pret. plusc. indic. 3 pl.', 'fut. perf. subj. 2 pl.', 'fut. perf. subj. 1 pl.', 'pot. simp. 2 pl.', 'pret. perf. indic. 2 sing.', 'pret. plusc. subj. 3 sing.', 'imperf. indic. 1 sing.', 'ger. comp.', 'pres. subj. 1 pl.', 'pot. simp. 1pl.', 'plusc. si mp. 3 sing.', 'imperf. indic. 3pl.', 'fut. indic. 1pl.', 'pret. plusc. subj. 2 sing.', 'imperf. indic. 3 sing.', 'plusc. simp. 1 pl.', 'pres. indic. 3 sing.', 'pret. plusc. subj. 2 pl.', 'pres. subj. 1 sing.', 'pot. simp. 3 sing.', 'pret. perf. indic. 2 pl.', 'pres. indic. 1 pl.', 'pot. simp. 2 sing.', 'pret. 2 pl.', 'pret. perf. indic. 3 sing.', 'pret. perf. subj. 3 sing.', 'pot. simp. 3pl.', 'fut. perf. indic. 3 pl.', 'pret. anter. 3 pl.', 'plusc. simp. comp. 3 sing.', 'fut. perf. indic. 2 sing.', 'pres. subj. 2sing.', 'pret. plusc. indic. 3 sing.', 'plusc. simp. 2 pl.', 'pret. plusc. indic. 1 pl.', 'pres. subj. 1pl.', 'imperf. indic. 1 pl.', 'plusc. simp. comp. 3 pl.', 'pres. subj. 2 pl.', 'imper. 2pl.', 'fut. indic. 2pl.', 'pret. plusc. subj. 3pl.', 'pret. anter. 2 pl.', 'pot. simp. 1 pl.', 'fut. indic. 3pl.', 'pret. 2pl.', 'pres. subj. 3 sing.', 'pret. 1 sing.', 'fut. perf. subj. 3 sing.', 'pret. perf. indic. 3 pl.', 'plusc. simp. 1 sing.', 'pres. subj. 2pl.', 'infinit.', 'fut. indic. 3 pl.', 'imperf. indic. 2 sing.', 'pret. plusc. subj. 1 pl.', 'pret. anter. 3 sing.', 'pret. anter. 1 pl.', 'pres. indic. 3pl.', 'pret. perf. indic. 3pl.', 'imperf. subj. 1 sing.', 'plusc. simp. comp. 1 pl.', 'fut. indic. 3 sing.', 'pres. subj. 2 sing.', 'pres. subj. 3 pl.', 'fut. perf. subj. 2 sing.', 'ger.', 'imperf. subj. 3 pl.', 'fut. subj. 1 pl.', 'pres. indic. 1 sing.', 'plusc. simp. 3 sing.', 'pret. perf. indic. 1 sing.', 'pret. plusc. indic. 2 sing.', 'pret. perf. subj. 2 pl.', 'fut. indic. 2 sing.', 'fut. subj. 2 sing.', 'pret. 1pl.', 'pret. plusc. subj. 3 pl.', 'imperf. indic. 2pl.', 'imperf. subj. 2 sing.', 'pres. indic. 2pl.', 'pret. 3 pl.', 'imperf. subj. 2 pl.', 'imperf. indic. 2 pl.', 'pret. plusc. indic. 2 pl.', 'p. a.', 'plusc. simp. 3 pl.', 'fut. indic. 1 sing.', 'pot. comp. 3 pl.', 'pret. anter. 2 sing.', 'imper. 2 sing.', 'pret. perf. subj. 1 pl.', 'imperf. subj. 1pl.', 'pret. plusc. indic. 1 sing.', 'pret. perf. subj. 3 pl.', 'pres. indic. 2 pl.', 'plusc. simp. 3pl.', 'pres. indic. 2 sing.', 'pret. plusc. subj. 1 sing.', 'imperf. indic.', 'imperf. subj. 1 pl.', 'fut. indic. 1 pl.', 'pret. 3 sing.', 'pres. indic. 3 pl.', 'pret. perf. indic. 1pl.', 'pret. anter. 1 sing.', 'imperf. indic. 1pl.', 'pret. perf. indic. 2pl.', 'pret. 3pl.', 'pret. plusc. indic. 3pl.', 'pret. 1 pl.', 'imperf. subj. 3pl.'}\n",
        "tatags = '|'.join(tags).replace('.', '\\.')\n",
        "# clas = set()\n",
        "pattern = r'(os?|[ae](ron|mos|d(es)?|s|n|t|r|ss?[ei](s|mos|des|n)?)?|(y|i|j)(ss?[ei](s|mos|des|n)?|d|t|mos|des|d[oa]s?|r(on)?|e?st(es?)?|o([ls][eoa]?s?)?|[ae](ron|s|mos|des|n|ndo|r([ea](s|mos|des|n)?)?|ss?[ei](s|mos|des|n)?)?)?|[ie]?ri?[ae](s|mos|des|n)?|ud[oa]s?|t[oa]s?)$'\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    if not isinstance(other, str):\n",
        "      forms = set()\n",
        "    else:\n",
        "      forms = set(eval(other)['Formas atestiguadas:\\xa0'] if other!= '{}' else [])\n",
        "      wirds = set()\n",
        "      for form in forms:\n",
        "        for subs in form.split(';'):\n",
        "          two = subs.split('–')\n",
        "          if len(two)==2:\n",
        "            # clas.add(two[0].strip())\n",
        "            wirds.add(re.sub(tatags, '', two[1]).strip())\n",
        "          else: wirds.add(re.sub(tatags, '', two[0]).strip())\n",
        "      #forms = set([re.sub(r'(.+)([oa]s?)', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    wirds = set(re.sub(pattern, '', p) for p in wirds if p.count(' ')==0 and p.count('(')==0 and p.count(')')==0)\n",
        "    wirds.discard(word[:-2])\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word[:-2]}.{'|'+'|'.join([form+\".\" for form in wirds if form]) if wirds and list(wirds)[0] else ''}\n",
        " gramm: verb\n",
        " paradigm: V_{word[-2]}\n",
        "\"\"\"\n",
        "    )\n",
        "    # lex.write(f\"{word}, ':', {wirds}\\n\")"
      ],
      "metadata": {
        "id": "vlpVAhGbSjDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# o|[ae](mos|d(es)?|s|n|t|r)?|(y|i)(mos|des|d[oa]s?|r|ist(es?)?|o|a|e(ron|s|mos|des|n|endo|r[ea](s|mos|des|n)?|ss?e(s|mos|des|n)?)?)?|[ie]?ri?[ae](s|mos|des|n)?\n",
        "pattern = r'(o|[ae](ron|mos|d(es)?|s|n|t|r|ss?[ei](s|mos|des|n)?)?|(y|i|j)(ss?[ei](s|mos|des|n)?|d|t|mos|des|d[oa]s?|r(on)?|e?st(es?)?|o([ls][eoa]?s?)?|[ae](ron|s|mos|des|n|ndo|r([ea](s|mos|des|n)?)?|ss?[ei](s|mos|des|n)?)?)?|[ie]?ri?[ae](s|mos|des|n)?|ud[oa]s?|t[oa]s?)$'\n",
        "a = {'ouiera contesçido', 'auie contesçudo', 'contesciendo', 'contesçe', 'contecer', 'contesçieran', 'contecera', 'contecie', 'contescio', 'contesciere', 'conteçudo', 'contesçudo', 'contesçio', 'conteciesse', 'contece', 'conteciera', 'contecer (l)a', 'contesçieron', 'contecieron', 'contescie', 'auie contecido', 'contescen', 'contesçra', 'contescido', 'contescran', 'conteçe', 'conteçie', 'contezcan', 'contesçiera', 'contescer', 'contecido', 'ouiesse contescido', 'contesçiesse', 'conteçen', 'contençer', 'conteçio', 'auie contescida', 'conteçrie', 'contesciol', 'conteçido', 'contesçrie', 'contecen', 'contesca', 'contecio', 'contesciesse', 'conteçra', 'conteciessen', 'contescien', 'conteçeran', 'a conteçudo', 'contesciessen', 'a contescido', 'contescida', 'contesciera', 'contescieran', 'contesce', 'contescra', 'conteçiera', 'contescrie', 'ayan contescido', 'auie conteçido', 'contescieron', 'contesçido'}\n",
        "a = {'a caesçio', 'acahesciesse', 'acaesçer (les) an', 'acayecen', 'acaescer (te) a', 'acaece', 'ouiesse acaecido', 'acaesçieran', 'accaecieren', 'acaese', 'acaeçe', 'accaeçcer', 'achaecera', 'acaecier', 'acaesciera', 'accaecer(l)an', 'acaescera', 'acaescio', 'accaeçeran', 'accaecyendo', 'acaeçio', 'accaeciendo', 'acaesçen', 'acaescer (les) an', 'accaeziendo', 'acaeçier', 'acaecyere', 'accaecyere', 'acaesçe', 'accaecer (les) an', 'acaeçieron', 'acaeçca', 'accaecen', 'acaecieren', 'acaesciendo', 'acaeçra', 'accaescera', 'auie acaecido', 'acaeçer (les) an', 'acaeçera', 'acaescrie', 'acaecio', 'acaescier', 'accaeçe', 'acaescen', 'acaesciessi', 'acaesçieren', 'ouiesse acaescido', 'acaescran', 'acahesçieron', 'acahescio', 'accaecyeren', 'acaesçrie', 'a caescie', 'accaecera', 'acaesçiera', 'acaesçiesse', 'acaesçido', 'acaecer(l)a', 'acaesçien', 'acaeçiere', 'acaecel(les) ye', 'accaeçran', 'accaeçen', 'acahesçien', 'acaescia', 'acaesçieron', 'acaescieren', 'acaeciera', 'a acaescido', 'acaesçerie', 'acaezen', 'acahescen', 'acahesciessen', 'acaescido', 'a caescio', 'auien acaescido', 'accaeçcan', 'acaesce', 'acahescieron', 'acahesciera', 'acaeçran', 'acaesciesse', 'acaesçio', 'accacieren', 'accaecyo', 'acahescien', 'acaeciesse', 'acaescieran', 'acaeze', 'acaeçieren', 'acaescer', 'accaece', 'acahesçe', 'accaecere', 'acaescidos', 'acaescieron', 'acaescien', 'accaecio', 'acaecer(l)an', 'acaescer(l)a', 'accaeçra', 'acaecie', 'acaesca', 'acaecera', 'accaeceran', 'a caesciesse', 'auien acaescidos', 'acaesçra', 'acaeciere', 'acaezca', 'acahescie', 'acaeçen', 'acaesçiere', 'accaecer (lis) an', 'accaecer', 'accaeçera', 'acaecen', 'acaeciessen', 'accaesce', 'acaezcan', 'acaesçer', 'accaecer (l)a', 'acahescer', 'acaesciessen', 'acaeceran', 'acaecieran', 'acaecieron', 'acaeçer', 'acaesçier', 'acaesciere', 'acaescie', 'acaeciendo', 'acaesçie', 'acaecer', 'a caecier', 'accaeciere'}\n",
        "a= {'aduzria', 'adugades', 'aduzre', 'aduzir (los) he', 'aduzrien', 'adux', 'a dozir', 'aduzir (l)e', 'aduxiemos', 'adugamos', 'aduchas', 'adozimos', 'adurie', 'aduzra', 'aduzriedes', 'adu', 'aduxesse', 'aduxieremos', 'adugan', 'aduxiste', 'aduzia', 'adozid', 'auie aducho', 'aduga', 'adugo', 'adugas', 'a duze', 'aduxieren', 'aduzir', 'a duxo', 'aduzie', 'adoxieron', 'aduxiera', 'adozie', 'aduzras', 'adozit', 'adozides', 'aduzes', 'adozia', 'aducho', 'adozir (los) emos', 'aduxier', 'aduxies', 'aduxien', 'aduzen', 'adozrie', 'aduziendo', 'aducha', 'a dozir (lo) as', 'aduze', 'aduzid', 'aduxiessen', 'aduzien', 'aduxiessemos', 'aduzrie', 'aduxiere', 'aduz', 'a duxiste', 'aduzimos', 'auemos aduchas', 'aduchos', 'aduxieran', 'aduxieron', 'aduziedes', 'adura', 'aduzran', 'aduxiestes', 'auedes aducho', 'adozir', 'auie aduchas', 'aduxeron', 'aduxiesse', 'aduremos', 'aduran', 'aduxist', 'aduxo'}\n",
        "a = {'aprendieron', 'aprendemos', 'apprendieron', 'aprendan', 'aprendas', 'aprendie', 'aprendudas', 'aprisiera', 'aprendet', 'aprisieren', 'aprendien', 'auien aprendido', 'apris', 'apriso', 'aprended', 'aprendiesse', 'apprendra', 'auia apreso', 'auie apreso', 'aprendiste', 'aprendades', 'aprendrien', 'aprendiessen', 'aprisiessen', 'aprende', 'aprendi', 'a prendie', 'aprendran', 'aprend', 'apprender', 'aprendio', 'aprendiedes', 'apprendas', 'a prendieredes', 'auie aprendudo', 'e aprendudo', 'aprendist', 'a prisiessen', 'apresiere', 'aprendo', 'aprendiemos', 'auiendo aprendudo', 'aprendremos', 'aprendiendo', 'aprisiesse', 'ouo aprendudas', 'aprisieran', 'aprendudo', 'aprendiera', 'aprisiestes', 'aprendimos', 'aprendido', 'ouo apreso', 'aprender', 'aprendieran', 'aprenden', 'aprenda', 'apreso', 'aprisieron', 'ouiesse apreso'}\n",
        "a = {'comjen', 'ouiesse comido', 'comiemos', 'comimos', 'comas', 'comiesse', 'comjeron', 'comieran', 'ouieres comido', 'comeras', 'comiessedes', 'combredes', 'combran', 'combras', 'comer', 'coman', 'comerien', 'comudos', 'comidas', 'comudo', 'comiere', 'comieron', 'comiera', 'comistes', 'aurien comido', 'combre', 'comidos', 'come', 'comieredes', 'comia', 'comiendo', 'ouieron comidos', 'conbran', 'a comuda', 'aya comido', 'auien comida', 'comi', 'combrie', 'comieres', 'comiestes', 'ouieron comido', 'comier', 'comida', 'comen', 'comel(lo)', 'comed', 'comie', 'comedes', 'a comido', 'comamos', 'comades', 'comido', 'comio', 'comien', 'comj', 'auie comido', 'comiessen', 'comet', 'comuda', 'a comudo', 'combremos', 'comjo', 'comjendo', 'comeran', 'conbrien', 'comjessen', 'coma', 'comieren', 'ouiemos comido', 'combrien', 'combra', 'ouo comida'}\n",
        "a = {'connosçiendo', 'connosçe', 'connoçran', 'connosçidos', 'connozca', 'connoscieron', 'connosçudo', 'connoscieren', 'connoscrien', 'connoçudas', 'connoz', 'ouiesse conosçido', 'connosciesse', 'connosciendo', 'conosçido', 'connosciste', 'conosçiessen', 'connosçien', 'connoscel(le)', 'conosçuda', 'conosca', 'connocer', 'connocieren', 'connosçredes', 'connoscio', 'conoscer', 'connoscremos', 'connosçudos', 'connoscedes', 'connoscemos', 'conoçudo', 'connosçrie', 'connocida', 'connosçieron', 'connosçre', 'connoscas', 'connosçran', 'connoçien', 'conosçieron', 'cognoscan', 'connosciemos', 'conosçer', 'connusçuda', 'conocidas', 'conosçio', 'connosciere', 'connoscien', 'connosçed', 'connocidas', 'connoçudo', 'connocen', 'conosçudo', 'conoscen', 'connosciera', 'conoscia', 'connoscan', 'connoçedes', 'connoscimos', 'connoscist', 'connoscudo', 'connosco', 'connosces', 'connocio', 'conoscio', 'connoscades', 'connosci', 'connocien', 'connoçuda', 'auie connosçudos', 'connocj', 'connociera', 'connosce', 'connoce', 'conosçien', 'connoscido', 'connosçio', 'connoscidas', 'connosciessen', 'connosced', 'connosçieran', 'connoceras', 'conoscan', 'connosçudas', 'connocieron', 'connoscie', 'connoscamos', 'connosca', 'conocer', 'conosco', 'ouiesse connosçudo', 'connosçer', 'connoçen', 'connoscida', 'conosçie', 'connocieres', 'ouieron conosçudas', 'connocie', 'connoscieres', 'connoscieran', 'connoçer', 'connosçuda', 'conosçidos', 'connoscudas', 'connoscudos', 'conosçudos', 'conosçia', 'conosciessen', 'connoscen', 'connozcas', 'ouiessen connosçudo', 'connociessen', 'connoscer', 'conoscieron', 'connociendo', 'connosçra', 'conosciesse', 'connosçiessen', 'connocer(l)ien', 'conosçudas', 'connoçras', 'conosçieren', 'connoscidos', 'connoscra'}\n",
        "a = {'conquiriessen', 'conquiriera', 'conquiridas', 'conquerira', 'conquirieron', 'con querir', 'auedes conquerido', 'conquerie', 'conquerimos', 'conquirrie', 'conquerire', 'auien conquerida', 'ouo conquerido', 'conquerido auie', 'conquiridos', 'auie conquiridos', 'conqueririen', 'conquerir (los) an', 'conquerre', 'conquiramos', 'conquiriesses', 'ouieron conquiridas', 'conqueriendo', 'conquerieron', 'ouiessen conquerida', 'conquerra', 'conquiriron', 'conqueriste', 'conquiriran', 'conqueril(los)', 'conquieren', 'conqueridas', 'conquerio', 'conquiri', 'conquerrie', 'conquirimos', 'conquiriesse', 'conquirieran', 'conquirir', 'auemos conquerido', 'conquerisse', 'conqueriran', 'conquerist', 'conquirio', 'conquerida', 'conquirida', 'conquirien', 'ouo conquerida', 'conquerido', 'ouiera conqueridas', 'conquiriendo', 'conquerir (las) a', 'conquerran', 'conquiriere', 'conquieres', 'conquirie', 'ouiese conquerida', 'conqueri', 'conqujrio', 'conqueriron', 'auiendo conqueridas', 'conquerir'}\n",
        "a = {'cresçer', 'cresciendo', 'creçidos', 'cresceras', 'creçier', 'crecie', 'cresced', 'crescieredes', 'crecidas', 'creciendo', 'cresçiesse', 'creceras', 'cresçudo', 'crescera', 'cresçido', 'creçeras', 'crescien', 'creçen', 'crescieran', 'crecera', 'crecieran', 'crecier', 'crecer', 'cresca', 'crecen', 'crecio', 'creçra', 'creciessen', 'creçiendo', 'ouo crescido', 'creced', 'crescas', 'crescet', 'creceran', 'creciesse', 'crescer', 'cresce', 'crescra', 'crecieren', 'cresçieran', 'gresçiera', 'cresçer (les) a', 'creçer (l)a', 'creçet', 'creçie', 'auien cresçudo', 'cresçieron', 'cresçe', 'crescer (nos) a', 'cresceran', 'creçio', 'crescieron', 'crescie', 'cresçrie', 'creçiera', 'cresçiendo', 'crescio', 'creçer', 'cresçie', 'creciere', 'crezca', 'crescido', 'cresciesse', 'creçe', 'crezcan', 'crescida', 'crecieron', 'creçiessen', 'crecries', 'creçran', 'crescan', 'crescrie', 'cresçran', 'crescen', 'crecien', 'crecer (gela) an', 'cresçen', 'crecidos', 'cresçida', 'cresciessen', 'crescrien', 'cresçio', 'cresciera', 'crece'}\n",
        "a = {'cubriesse', 'crubiol', 'crobi', 'crubas', 'crubiron', 'crobiesse', 'cobriran', 'cubre', 'cubririen', 'cubiertas', 'cruben', 'cubiertos', 'cubriras', 'cubrieron', 'cubra', 'cubriessen', 'cubriendo', 'crubiendo', 'cubren', 'cubrio', 'crubie', 'cruba', 'cobrir', 'crubrieron', 'crubiera', 'crube', 'cobrieron', 'cobierto', 'crubire', 'cubierto', 'crobiron', 'cobiertos', 'crubisse', 'cubririe', 'crubieron', 'crobisen', 'crubist', 'crobieran', 'cobrira', 'cubran', 'crubiesse', 'cobrieres', 'cubrie', 'crobira', 'crubien', 'cubras', 'crubrio', 'cubrir', 'crobir', 'crobistes', 'cubierta', 'cubrien', 'crubio', 'crubiran', 'cobriesse', 'crobieron', 'crubiedes', 'crobrir (te) a', 'crubririe'}\n",
        "a = {'conplieron', 'cumplamos', 'complir (la) as', 'complido', 'compliran', 'cumpliera', 'conplira', 'cumplio', 'compliere', 'cumplidas', 'compliremos', 'cumplas', 'conplir', 'compliron', 'complieres', 'ouiesse cumplido', 'cunplieron', 'cumplen', 'cumplirie', 'cumplires', 'compliras', 'cunplan', 'cumplisse', 'complissen', 'cumpliste', 'ouiere complida', 'cumplir (te lo) he', 'compliessen', 'complidas', 'ouissen complido', 'complieron', 'cumpliendo', 'cumplida', 'cumpliessen', 'conplidas', 'cumplira', 'complien', 'cumplire', 'cumpliredes', 'cunplio', 'cumplir (s)a', 'conplien', 'cumple', 'conplidos', 'cumplieren', 'cumplieres', 'cumplades', 'cunpla', 'complir (s)an', 'complira', 'cunplian', 'conpliremos', 'cumpla', 'complid', 'complen', 'cumplieredes', 'cumpliran', 'cumpliras', 'conplir (s)a', 'cumplido', 'cumplan', 'cunpliran', 'cumpliestes', 'conplie', 'complieren', 'complir', 'cumplir', 'ayan complida', 'cumpliremos', 'complio', 'cunplira', 'auras complida', 'ouo complido', 'ayades cumplido', 'conpliran', 'cumplirien', 'complil(lo)', 'complida', 'complie', 'complirie', 'cunple', 'conprido', 'cunpliesse', 'cumpliere', 'complir se(a)', 'cumplieron', 'conplio', 'complire', 'cumplidos', 'cunplen', 'compliesse', 'conpliesen', 'complirien', 'cumplien', 'cumpliesse', 'cumplir (set)a', 'complides', 'complir (la) e', 'cunpliessen', 'conpliese', 'compliste', 'cumplist', 'cumplie'}\n",
        "a = {'deffiende', 'deffendiemos', 'deffendido', 'defendiera', 'defiende', 'defendien', 'deffendieron', 'deffendries', 'defendiese', 'deffendiessemos', 'defende', 'deffendiesse', 'deffiendan', 'defendel(los)', 'deffendien', 'defendudas', 'deffendieran', 'defendre', 'deffendio', 'defendudo', 'defendieron', 'deffende', 'defendas', 'deffendudo', 'defender (l)an', 'defendrie', 'defiendan', 'deffendiera', 'deffenden', 'defiendas', 'deffendidas', 'deffendet', 'defiendo', 'defenduda', 'deffendi', 'defendemos', 'deffendre', 'auie defendido', 'defendra', 'deffendas', 'defendras', 'deffendra', 'deffendiendo', 'defenda', 'defenderedes', 'defendi', 'deffendiessen', 'auie deffendido', 'defendiesse', 'defendido he', 'defendo', 'defender', 'defendido', 'defendio', 'deffienden', 'defendiestes', 'defendie', 'deffiendas', 'deffendudas', 'defienden', 'defendet', 'deffiendo', 'defendiendo', 'deffendo', 'deffender', 'defendiere', 'defendades', 'deffienda', 'deffendie', 'deffendrien', 'deffendies', 'defendiessen', 'defendida', 'deffenda', 'deffenduda', 'deffendrie', 'defendudos', 'he defendido', 'as defendido', 'defendidos', 'deffendia', 'defienda'}\n",
        "a = {'destruxeron', 'destruyst', 'destruyra', 'destruyr (ge la) an', 'destruxesse', 'destroyran', 'destruyr (se)a', 'destruyrie', 'estruyr', 'destroyesse', 'destroysse', 'estroyen', 'destruyas', 'destruen', 'destruydas', 'destruyria', 'destroydos', 'destruir (s)a', 'destruir', 'destruyo', 'estroyr', 'destroydo', 'destruir (les) as', 'destruido', 'destruyendo', 'destruyesse', 'destroyeran', 'destruyere', 'destruyr (los) an', 'destroyessen', 'destroiras', 'destroya', 'destruira', 'destruyan', 'estroyendo', 'destroyera', 'destroyr (los) e', 'destrue', 'estroyda', 'destroye', 'destruidos', 'destroyen', 'destruye', 'destruire', 'destroido', 'destruxo', 'destroyrie', 'destroyl(los)', 'estroydos', 'destroyda', 'destruyda', 'destruxieron', 'destroyr (s)a', 'destruyera', 'destruymos', 'destroyries', 'dextruxo', 'destroyr (uos) he', 'destruxiesse', 'destruyen', 'destruyr (los) a', 'destruyredes', 'destroyd', 'destruyre', 'destroyre', 'destruyessemos', 'destruyeran', 'destruyrien', 'destroyeron', 'destroil(la)', 'destruyd', 'destruyras', 'destruyr (nos) a', 'destroyendo', 'destroir', 'destruyamos', 'destroyra', 'auien destroidas', 'destruida', 'destroyrien', 'destruir (los) an', 'destruya', 'destruyr', 'destroyron', 'destroida', 'destruyessen', 'destroidos', 'destruydo', 'destruysse', 'destroyil(los)', 'destroidas', 'destroyssen', 'estroydo', 'destroy', 'destruyeron', 'destroydas', 'destruyran', 'destroyr', 'ouo destroidos', 'destruydos'}\n",
        "\n",
        "\n",
        "\n",
        "b = set(re.sub(pattern, '', p) for p in a if p.count(' ')==0 and p.count('(')==0 and p.count(')')==0)\n",
        "# for p in a:\n",
        "#   print(p, re.sub(pattern, '', p))\n",
        "print(b)"
      ],
      "metadata": {
        "id": "5RkOlclzF6LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SuperIrregular\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: ser\n",
        " stem: s.\n",
        " gramm: verb\n",
        " paradigm: V_serS\n",
        "\"\"\")\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: ser\n",
        " stem: e.|he.\n",
        " gramm: verb\n",
        " paradigm: V_serE\n",
        "\"\"\")\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: ser\n",
        " stem: f.\n",
        " gramm: verb\n",
        " paradigm: V_serF\n",
        "\"\"\")\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: ir\n",
        " stem: y.|i.|j.\n",
        " gramm: verb\n",
        " paradigm: V_irY\n",
        "\"\"\")\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: ir\n",
        " stem: f.\n",
        " gramm: verb\n",
        " paradigm: V_irF\n",
        "\"\"\")\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: ir\n",
        " stem: v.|u.\n",
        " gramm: verb\n",
        " paradigm: V_irV\n",
        "\"\"\")\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: saber\n",
        " stem: se.\n",
        " gramm: verb,prs,ind,1sg\n",
        " paradigm: ZERO\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: haber\n",
        " stem: he.|e.\n",
        " gramm: verb,prs,ind,1sg\n",
        " gloss: VERB.PRS.IND.1SG\n",
        " paradigm: ZERO\n",
        "\"\"\")\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: haber\n",
        " stem: as.\n",
        " gramm: verb,prs,ind,2sg\n",
        " gloss: VERB.PRS.IND.2SG\n",
        " paradigm: ZERO\n",
        "\"\"\")\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: haber\n",
        " stem: a.|ha.|ah.\n",
        " gramm: verb,prs,ind,3sg\n",
        " gloss: VERB.PRS.IND.3SG\n",
        " paradigm: ZERO\n",
        "\"\"\")\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: haber\n",
        " stem: an.|han.\n",
        " gramm: verb,prs,ind,3pl\n",
        " gloss: VERB.PRS.IND.3PL\n",
        " paradigm: ZERO\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "xfDg7yrCG90g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Unidades pluriverbales"
      ],
      "metadata": {
        "id": "_8K2T5ySP6a_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verbos"
      ],
      "metadata": {
        "id": "-aIrdo_5VgbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#como verbos mas no verbos\n",
        "import re\n",
        "dict_extr_R = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+[aie]r\\b\")) &\n",
        "    ((df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "    (\n",
        "        (df['WORD'].isin({'adar', 'atacir', 'azar', 'azingar', 'bezoar', 'cantar', 'cuer', 'haber', 'juglar', 'lugar', 'mar', 'menester', 'mujer', 'pesar', 'poder', 'saber', 'ser'}))\n",
        "        &~df.index.isin({5363, 7671, 7804, 8346, 8682, 9002})\n",
        "    ))\n",
        "]\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_extr_R['WORD'], dict_extr_R['ADDITIONAL_INFO']):\n",
        "    forms = set([re.sub(r'(.+)es', r'\\1', form) if word[-2:]!='es' else re.sub(r'(.+ess?)es', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form.strip()+\".\" for form in forms if form.strip().count(' ') == 0]) if forms else ''}\n",
        " gramm: noun\n",
        " paradigm: NOM_C\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "qu2ZMRwdP-An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "dict_extr_R = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+[^aie]r\\b\")) &\n",
        "    (df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "    (df['WORD']!='por')\n",
        "]\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_extr_R['WORD'], dict_extr_R['ADDITIONAL_INFO']):\n",
        "    forms = set([re.sub(r'(.+)es', r'\\1', form) if word[-2:]!='es' else re.sub(r'(.+ess?)es', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form.strip()+\".\" for form in forms if form.strip().count(' ') == 0]) if forms else ''}\n",
        " gramm: noun\n",
        " paradigm: NOM_C\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "1sT2ZNDWd4mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_extr_R.drop('EXAMPLES', axis=1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cPveD5OAQKQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nomina"
      ],
      "metadata": {
        "id": "7uSkxxfWblbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#in -o\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+o\\b\")) &\n",
        "    (df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "    (df['WORD']!='no') & (df['WORD']!='como')\n",
        "]\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    if not isinstance(other, str):\n",
        "          forms = set()\n",
        "    else:\n",
        "          forms = set(eval(other)['Formas atestiguadas:\\xa0'])\n",
        "    if any([re.fullmatch(r'.+as?', form) for form in forms]):\n",
        "        word = re.sub(r'(.+)(o)', r'\\1', word)\n",
        "        if not isinstance(other, str):\n",
        "          forms = set()\n",
        "        else:\n",
        "          forms = set([re.sub(r'(.+)([oa]s?)', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "        forms.discard(word)\n",
        "        lex.write(\n",
        "            f\"\"\"-lexeme\n",
        " lex: {word+'o'}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms and list(forms)[0] else ''}\n",
        " gramm: adj\n",
        " paradigm: ADJ\n",
        "\"\"\"\n",
        "        )\n",
        "    else:\n",
        "      if not isinstance(other, str):\n",
        "          forms = set()\n",
        "      else:\n",
        "          forms = set([re.sub(r'(.+)s', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "      forms.discard(word)\n",
        "      lex.write(\n",
        "          f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms and list(forms)[0] else ''}\n",
        " gramm: noun\n",
        " paradigm: NOM\n",
        "\"\"\"\n",
        "      )"
      ],
      "metadata": {
        "id": "N9bL2cNcbmnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in -a\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+a\\b\")) &\n",
        "    (df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "    (~df['WORD'].isin({'afuera', 'cada', 'contra', 'defuera'}))\n",
        "]\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    if 'Formas atestiguadas:\\xa0' in eval(other):\n",
        "      forms = set([re.sub(r'(.+)s', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    else:\n",
        "      forms = set()\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: noun\n",
        " paradigm: NOM\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "FBkHBzEwjup7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#other V\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+[eiu]\\b\", na=False)) &\n",
        "    (df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "    (~df['WORD'].isin({'leve', 'su', 'tu', 'sobre', 'tarde', 'que', 'qui'})) &\n",
        "    ((~df['WORD'].str.strip().str.contains(r\"(ante|i?ente)$\", regex=True, na=False))|\n",
        "   ( df['WORD'].isin({'frente', 'gente', 'mente', 'occidente', 'oriente'})))\n",
        "]\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    forms = set([re.sub(r'(.+)s', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: noun\n",
        " paradigm: NOM\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "WwqFQH8Sl8TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_noun_V.drop('EXAMPLES', axis=1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BCv2OiCUmGhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adj in V-o\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    (df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+[eiu]\\b\", na=False)) &\n",
        "    ((df['WORD'].isin({'leve','tarde'})) |\n",
        "    (df['WORD'].str.strip().str.contains(r\"(ante|i?ente)$\", regex=True, na=False))) &\n",
        "    (~df['WORD'].isin({'frente', 'gente', 'mente', 'occidente', 'oriente'}))\n",
        "]\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    word = re.sub(r'(.+)(e)', r'\\1', word)\n",
        "    if not isinstance(other, str):\n",
        "      forms = set()\n",
        "    else:\n",
        "      forms = set([re.sub(r'(.+)(es?)', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word+'e'}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: adj\n",
        " paradigm: ADJ_e\n",
        "\"\"\"\n",
        "  )"
      ],
      "metadata": {
        "id": "9BN_W0HInowL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in C-r\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    (df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+[^aeiour]\\b\", na=False))&\n",
        "    (~df['WORD'].isin({'antes', 'así', 'bien','ambos','azul','especial', 'demás', 'mientras', 'más', 'menos', 'hoy', 'pues', 'pos', 'oriental', 'occidental', 'tal'}))\n",
        "]\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    if 'Formas atestiguadas:\\xa0' not in eval(other):\n",
        "      forms = set()\n",
        "    else:\n",
        "      forms = set([re.sub(r'(.+)s', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: noun\n",
        " paradigm: NOM\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "xRHlC-sCrfRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rest of these\n",
        "import re\n",
        "dict_adj_C = df[\n",
        "    (df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "    (df['WORD'].str.strip().str.fullmatch(r\".+[^aeiour]\\b\", na=False))&\n",
        "    (df['WORD'].isin({'azul','especial', 'demás', 'oriental', 'occidental', 'tal'}))\n",
        "]\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_adj_C['WORD'], dict_adj_C['ADDITIONAL_INFO']):\n",
        "    if not isinstance(other, str):\n",
        "      forms = set()\n",
        "    else:\n",
        "      forms = set([re.sub(r'(.+)(es|(?<=a)s)\\b', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "      forms.discard(word)\n",
        "      lex.write(\n",
        "  f\"\"\"-lexeme\n",
        "  lex: {word}\n",
        "  stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        "  gramm: adj\n",
        "  paradigm: ADJ_C\n",
        "  \"\"\"\n",
        "    )\n",
        "dict_noun_V = df[\n",
        "    (df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "    (df['WORD'].isin({'antes', 'así', 'bien', 'demás', 'mientras', 'más', 'menos', 'hoy', 'afuera', 'defuera', 'solamente', 'no', 'como'}))\n",
        "]\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    if 'Formas atestiguadas:\\xa0' not in eval(other):\n",
        "      forms = set()\n",
        "    else:\n",
        "      forms = set(eval(other)['Formas atestiguadas:\\xa0'])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: adv\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "    )\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: ambos\n",
        " stem: amb.\n",
        " gramm: adj\n",
        " paradigm: ADJ\n",
        "\"\"\"\n",
        "    )\n",
        "  lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: cada\n",
        " stem: cada.\n",
        " gramm: adj\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "WA9t6_sGueFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_noun_V.drop('EXAMPLES', axis=1)"
      ],
      "metadata": {
        "id": "owToWkJ0rdsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ál"
      ],
      "metadata": {
        "id": "-XPmMX1mFJgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#interj\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    df['POS'].str.strip() == 'interj.'\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    forms = set(eval(other)['Formas atestiguadas:\\xa0'])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: interj\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "KzurPbjtFL5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adv\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    (df['POS'].str.strip() == 'adv.')\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    forms = set(eval(other)['Formas atestiguadas:\\xa0'])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: adv\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "WITaDfXEHA6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prep\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    (df['POS'].str.strip() == 'prep.')|\n",
        "    (\n",
        "            (df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "            (df['WORD'].isin({'por', 'contra', 'sobre', 'pos'}))\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    forms = set(eval(other)['Formas atestiguadas:\\xa0'])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: prep\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "UE4dx6WtHZG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conj\n",
        "import re\n",
        "dict_noun_V = df[\n",
        "    (df['POS'].str.strip() == 'conj.')|\n",
        "    (\n",
        "            (df['POS'].str.strip() == 'Unidades pluriverbales:') &\n",
        "            (df['WORD'].isin({'pues', 'que', 'como'}))\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_noun_V['WORD'], dict_noun_V['ADDITIONAL_INFO']):\n",
        "    forms = set(eval(other)['Formas atestiguadas:\\xa0'])\n",
        "    forms.discard(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {word}.{'|'+'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: conj\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "vKa2WEy2IQlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['POS'].value_counts()"
      ],
      "metadata": {
        "id": "a1bz1KWFIis7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pronombres"
      ],
      "metadata": {
        "id": "qpll6fumxZz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfi = df[df['POS'] == 'contracc. ']"
      ],
      "metadata": {
        "id": "6hwqCi3zHnlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfi"
      ],
      "metadata": {
        "id": "_AXN9gbyIntq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['POS'] == 'pron. '].drop('EXAMPLES', axis=1)"
      ],
      "metadata": {
        "id": "ROOPWVRMTXES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pronomina en -e/o\n",
        "import re\n",
        "dict_adj_V = df[\n",
        "    df.index.isin({596, 1062, 1064, 1065, 4669, 7054})\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_adj_V['WORD'], dict_adj_V['ADDITIONAL_INFO']):\n",
        "    if not isinstance(other, str):\n",
        "      forms = set()\n",
        "    else:\n",
        "      forms = set([re.sub(r'(.+)([eoa]s?)', r'\\1', form) for form in set(eval(other)['Formas atestiguadas:\\xa0'])])\n",
        "    forms.add(re.sub(r'(.+)([eo])', r'\\1', word))\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: pron\n",
        " paradigm: PRON\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "MI2295-Ax7Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pronomina immutabilia\n",
        "import re\n",
        "dict_adj_V = df[\n",
        "    (df.index.isin({419, 3053, 6978, 8158, 8174, 8445, 9086})) |\n",
        "    (df['WORD']=='qui')\n",
        "]\n",
        "\n",
        "\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "  for word, other in zip(dict_adj_V['WORD'], dict_adj_V['ADDITIONAL_INFO']):\n",
        "    if not isinstance(other, str):\n",
        "      forms = set()\n",
        "    else:\n",
        "      forms = set(eval(other)['Formas atestiguadas:\\xa0'])\n",
        "    forms.add(word)\n",
        "    lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: {word}\n",
        " stem: {'|'.join([form+\".\" for form in forms if form.count(' ') == 0]) if forms else ''}\n",
        " gramm: pron\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "6-bC-DTo02P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pronomina personalia\n",
        "with open('lexemes.txt', 'a') as lex:\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: yo\n",
        " stem: yo.|io.\n",
        " gramm: pron,1sg,nom\n",
        " gloss: PRON.1SG.NOM\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: yo\n",
        " stem: m.\n",
        " gramm: pron,1sg\n",
        " gloss: PRON.1SG\n",
        " paradigm: PRON_yo\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: tú\n",
        " stem: t.\n",
        " gramm: pron,2sg\n",
        " gloss: PRON.2SG\n",
        " paradigm: PRON_tu\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: él\n",
        " stem: e.|é.\n",
        " gramm: pron,3\n",
        " paradigm: PRON_el1\n",
        "\"\"\"\n",
        "    )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: él\n",
        " stem: l.\n",
        " gramm: pron,3\n",
        " gloss: PRON.3\n",
        " paradigm: PRON_el2\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: nos\n",
        " stem: n.\n",
        " gramm: pron,1pl\n",
        " gloss: PRON.1PL\n",
        " paradigm: PRON_nos\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: vos\n",
        " stem: v.|u.\n",
        " gramm: pron\n",
        " gramm: pron,2pl\n",
        " gloss: PRON.2PL\n",
        " paradigm: PRON_os\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: vos\n",
        " stem: os.\n",
        " gramm: pron\n",
        " gramm: pron,2pl,acc\n",
        " gloss: PRON.2PL.ACC\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: vos\n",
        " stem: os.\n",
        " gramm: pron\n",
        " gramm: pron,2pl,dat\n",
        " gloss: PRON.2PL.DAT\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: vos\n",
        " stem: os.\n",
        " gramm: pron\n",
        " gramm: pron,2pl,abl\n",
        " gloss: PRON.2PL.ABL\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: se\n",
        " stem: s.\n",
        " gramm: pron\n",
        " gloss: PRON\n",
        " paradigm: PRON_se\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: él\n",
        " stem: se.|ge.|ie.|je.\n",
        " gramm: pron,3,dat,sg\n",
        " gloss: PRON.3.DAT.SG\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: él\n",
        " stem: se.|ge.|ie.|je.\n",
        " gramm: pron,3,dat,pl\n",
        " gloss: PRON.3.DAT.PL\n",
        " paradigm: ZERO\n",
        "\"\"\"\n",
        "      )\n",
        ""
      ],
      "metadata": {
        "id": "Hxd4cNcS1vv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Articula"
      ],
      "metadata": {
        "id": "LnKP-4ClFx2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('lexemes.txt', 'a') as lex:\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: el\n",
        " stem: l.\n",
        " gramm: art,def,masc,sg\n",
        " gloss: ART.DEF.M.SG\n",
        " paradigm: ART_el\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: el\n",
        " stem: el.|ell.\n",
        " gramm: art\n",
        " gloss: ART\n",
        " paradigm: ART_el\n",
        "\"\"\"\n",
        "      )\n",
        "      lex.write(\n",
        "f\"\"\"-lexeme\n",
        " lex: un\n",
        " stem: u.|v.\n",
        " gramm: art\n",
        " gloss: ART\n",
        " paradigm: ART_un\n",
        "\"\"\"\n",
        "      )"
      ],
      "metadata": {
        "id": "qLg1HHuXF5F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Uniparser"
      ],
      "metadata": {
        "id": "eYabhC5jvsa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install uniparser_morph"
      ],
      "metadata": {
        "id": "uhyhIWAbvucK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from uniparser_morph import Analyzer\n",
        "a = Analyzer()\n",
        "a.lexFile = \"lexemes.txt\"\n",
        "a.paradigmFile = \"/content/project-753/paradigms.txt\"\n",
        "a.verbose = True\n",
        "a.load_grammar()"
      ],
      "metadata": {
        "id": "4ubLS0ivvyiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyses = a.analyze_words(['el', \"la\", 'le', 'li'])\n",
        "print(analyses)"
      ],
      "metadata": {
        "id": "Kh_6RuXAvzBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyses = a.analyze_words('ovo')\n",
        "# If you pass a single string, you will get a list of Wordform objects\n",
        "# The analysis attributes are stored in its properties\n",
        "# as string values, e.g.:\n",
        "for ana in analyses:\n",
        "        print(ana.wf, ana.lemma, ana.gramm, ana.gloss)\n",
        "        print([ana.gramm, ana.gloss])"
      ],
      "metadata": {
        "id": "WbtLDvAhrsw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "MeqfP2zlz3T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "test = [(lambda x: {\"word\": x[0], \"label\": set(x[1].split(',')), \"predicted\": [set(prediction.gramm.split(',')) for prediction in a.analyze_words(x[0])]})(line.split(':')) for line in re.split(r\"\\n|\\n\\n\", open('/content/project-753/test.txt', 'r').read().strip()) if line and line[0]!='-']\n",
        "test[1]"
      ],
      "metadata": {
        "id": "3r2yGwwOz7Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "right, wrong, none = [],[],[]\n",
        "for item in test:\n",
        "  word, corr, preds = item.values()\n",
        "  if not list(preds[0])[0]:\n",
        "    none.append(item)\n",
        "  elif any([corr==pred for pred in preds]):\n",
        "    right.append(item)\n",
        "  else:\n",
        "    wrong.append(item)\n",
        "num_right, num_wrong, num_none, num = len(right), len(wrong), len(none), len(test)\n",
        "print(f'{num_right}/{num} of predictions are correct.\\n{num_wrong}/{num} of predictions are wrong.\\n{num_none}/{num} were not parsed.')"
      ],
      "metadata": {
        "id": "3dDLlAOgoqgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong"
      ],
      "metadata": {
        "id": "_Uyfc3d5qCab"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}